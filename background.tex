\section{Virtual Reality}
With the launch and success of modern technologies like Oculus Rift, HTC Vive or Playstation VR (Figure \ref{fig:CONTROLLERS}), today’s virtual reality (VR) is mostly associated with a head-mounted device that provides this experience for the wearer. Virtual reality headsets combine a stereoscopic head-mounted display (HMD), stereophonic sound, and sensors like gyroscopes or accelerometers for head motion tracking. The main goal of these devices is to fool user’s senses, make him feel present and immersed in virtual reality. A person using such equipment is able to move and look around artificial world. Usually users can also interact with its features in some way, using specially designed controllers. Today VR headsets are mostly used for gaming, simulations, education, and other entertainment purposes.

\begin{figure}[th]
\centering
\includegraphics[width=1\textwidth]{img/headsets.png}
\caption{Modern popular VR headsets: Oculus Rift and Playstation VR (image source: \cite{OCULUS_HEADSET}\cite{PSVR_HEADSET})}
\label{fig:CONTROLLERS}
\end{figure}

The concept of virtual reality is evolving and changing quickly. The technologies we use now will probably become obsolete in next 5 years. To describe what virtual Reality really means, we must be broad enough to enclose what it meant in the past, what it is today, and what it can become in the future. S. M. LaValle in his book \cite{VR_BOOK} tries this approach to define VR in general way. The four key concepts which appear in his VR definition are:

\begin{itemize}
\item \textit{Targeted behavior}: The experience from the real world we try to replicate. It could be anything from walking, dancing, swimming, shooting arrows, etc.
\item \textit{Organism}: Any life form can be the user of VR. In the past it was tested even on animals like cockroaches, fishes, monkeys and rodents.
\item \textit{Artificial sensory stimulation}: With the use of available equipment and technology, organism’s senses are tricked to make him feel present in artificial reality.
\item \textit{Awareness}: While being immersed in VR, the user should be oblivious to any interference. Feeling presence in this altered or another world is accepted as natural.
\end{itemize}

Virtual reality has a long history and can be traced back even to 1962, when Morton Heilig built a machine called Sensorama. It could provide body tilting, supply stereo sound, display stereoscopic 3-D images, and was able to trigger tracks of aromas and wind during the film \cite{SENSORAMA}. Later in 1968, Ivan Sutherland invented what is regarded as the first head-mounted display device: The Sword of Damocles. The system provided basic user interface and realism, the graphics of created VR were simple wire-frame model rooms \cite{DAMOCLES}. The device was so heavy that it had to be attached to the ceiling with a mechanical arm (Figure \ref{fig:FIRST_VR}). In the next years VR devices were mainly used for flight simulation, military training, medical purposes and automobile design. With the advancements in technology and the launch of an affordable high-quality VR headsets, virtual reality became more accessible for video game players. Today we are witnessing an exciting rebirth of interest in VR, not only in entertainment industry but also in academic research.

\begin{figure}[th]
\centering
\includegraphics[width=0.9\textwidth]{img/first_vr.png}
\caption{The Sensorama and The Sword of Damocles, first attempts at creating virtual reality (image source: \cite{SENSORAMA_IMAGE}\cite{DAMOCLES})}
\label{fig:FIRST_VR}
\end{figure}

\section{VR input methods}

As more companies enter the VR headset market, we can see the rapid technological advancement in input devices. Authors of the article \textit{State of the Art of Virtual Reality Technology} \cite{VR_TECHNOLOGY} identified three different categories for devices handling input in VR: controllers, navigation devices and tracking technologies. Most of the controllers for VR headsets are hand worn and provide 6DoF (Six Degrees of Freedom) tracking information. They are usually equipped with buttons for discrete input, and top-mounted touchpads or joysticks for analog input. For example, Vive Controller (Figure \ref{fig:CONTROLLERS_IMAGE}) features 24 sensors, a multi-function trackpad and a dual-stage trigger \cite{VIVE_IMAGE}.

\begin{figure}[th]
\centering
\includegraphics[width=1\textwidth]{img/modern_controllers.png}
\caption{Modern VR controllers: The Oculus Touch and HTC Vive Controller (image source: \cite{VR_TECHNOLOGY}\cite{VIVE_IMAGE})}
\label{fig:CONTROLLERS_IMAGE}
\end{figure}

The illusion of traversing an endless space can be achieved with the help of navigation devices which are an input source for moving in the virtual environment. Most devices in this category act similar to traditional treadmills allowing movement in one direction. Some of them allow motion on a two-dimensional plane or function like the slidemills. For example, Virtuix Omni (Figure \ref{fig:VIRTUX_IMAGE}) is a concave platform with a low-friction surface which allows locomotive motion in any direction. There are also attempts at creating devices less expensive and more affordable to general public. Google is currently working on motorized shoes that allow an endless movement in a limited space \cite{VR_SHOES}. Other researchers try to use devices which were not specially designed for virtual reality. For instance, A. Aguirre in his master thesis \cite{JOYSTICK} describes the process of navigation in VR through leaning on Wii Balance Board.

\begin{figure}[th]
\centering
\includegraphics[width=0.85\textwidth]{img/vr_threadmills.png}
\caption{Omnidirectional treadmills: Virtuix Omni and WalkMouse (image source: \cite{VR_TECHNOLOGY})}
\label{fig:VIRTUX_IMAGE}
\end{figure}

There are currently two approaches for motion tracking technologies. First is full body tracking which focuses on posture and upper body of the users. Second is gesture tracking which is usually achieved optically or with devices worn on hands. Full body tracking is commonly implemented using magnetic tracking or Inertial Measurement Units (IMUs), providing six degrees of freedom by placing orthogonally to each other accelerometers, gyroscopes and magnetometers. IMUs are used to perform rotational tracking for the controllers and HMDs. They measure the rotational movements of the yaw, pitch, and roll. Valve came up with different approach, their inside-out Lighthouse tracking system involves two Base Stations that scan the tracked space with lasers \cite{VIVE}. These Base Stations (Figure \ref{fig:BASE_STATIONS}) are small cube-shaped devices placed in opposite sides of the room. They constantly sweep the area with non-visible lights that the receptors on the HMDs and controllers intercept. The stations serve as reference points for these tracked devices and allow them to figure out where they are in the 3D space. 

Gesture tracking can be achieved with numerous input devices that are not necessarily designed for VR. For example, Leap Motion technology is designed to track hands and fingers with low processing power, high accuracy, and near-zero latency \cite{LEAP_MOTION}. It uses three infrared LEDs and two monochromatic IR cameras to observe a hemispherical area up to a distance of about 1 meter.  The Leap Motion controller can be attached on top of any virtual reality headset. There are also various sensor technologies designed to be worn like a glove. Besides tracking gestures such as bending of fingers, they sometimes offer additional functionality. One of these data gloves called Gloveone, enables users to feel and touch any virtual object that they can see in VR headsets \cite{GLOVEONE}. There are 10 actuators distributed along the fingertips and palm of the glove, which vibrate independently at different intensities and frequencies, reproducing touch sensations.

\begin{figure}[th]
\centering
\includegraphics[width=0.65\textwidth]{img/base_stations.png}
\caption{Vive Base Stations: inside-out laser-based tracking system (image source: \cite{VIVE})}
\label{fig:BASE_STATIONS}
\end{figure}

\section{VR sickness}

While VR is a promising technology, which quickly gains on popularity, it still has a great challenge and safety issue to overcome. Virtual reality sickness (also called cybersickness) is a group of unpleasant symptoms which can occur during an exposure to virtual environment. These symptoms can last from few minutes to even days and most often include headache, disorientation, sweating, eye strain, fullness of stomach, pallor, vomiting, nausea, dryness of mouth, vertigo, or ataxia \cite{VRSYMPTOMSTIME}. Although similar to motion sickness, VR sickness is different in that it can occur with visual stimulation alone. Motion sickness is mainly induced with vestibular stimulation, while vision can be a contributing cause. It is also sufficiently different from simulator sickness which tends to occur as a result of oculomotor disturbances, with disorientation being the main symptom in VR sickness \cite{VRANDSIMULATORSICKNESS}. Beyond the sickness itself, these undesirable symptoms may have other consequences. VR sickness could reduce the efficiency of VR training and rehabilitation tools, or it could even discourage users from trying virtual reality ever again. Currently, there are many speculations as to why VR sickness occurs. J. J. LaViola in his article about cybersickness \cite{VRSYMPTOMS} describes three following main theories: 

\begin{itemize}
\item \textit{The sensory conflict theory}: The most commonly accepted theory which is based on the assumption that inconsistency between the vestibular and visual sense cause a perceptual conflict within the body. These sensory conflicts may appear when the sensory input is not the stimulus that the user expected based on his prior experience. Taking this into consideration, the symptoms of VR sickness could be reduced if the sensory information causing self-motion are in agreement with each other.
\item \textit{The poison theory}: The theory tries to explain VR sickness from an evolutionary standpoint. It is based on the premise that the consumption of poison leads to physiological problems which affects the coordination of sensory information. This serves as an early warning system that causes nausea and vomiting which may increase the chances of survival. The conflicting stimulation found in VR can cause the misreading of sensory inputs and make the body think that it has been poisoned.
\item \textit{The postural instability theory}: This theory focuses on the concept that the main objective of human body is to sustain postural stability at all time. If the control can't be maintained, the motion sickness symptoms appear. In many virtual environments, there are some optically specified movements which are abnormal for inexperienced users. As a result, their postural control strategies may fail.
\end{itemize}

There are also other contributing factors to VR sickness, not necessarily related to any of these three theories. Various technical aspects can have a great impact on sickness symptoms, such as mismatched motion, low refresh rate, or not achieving the target frame rate. Head position tracking is a vital element of any virtual environment, however, current tracking systems are not completely accurate. They can report information with error which leads to uncontrollable movement and dizziness of the user. Studies have shown that increasing field of view (FOV) tends to increase VR sickness. Implementing methods to dynamically restrict FOV can help combat this effect \cite{DYNAMICFOD}. Several other techniques are used to reduce sickness symptoms. For example, introducing static visual background (Figure \ref{fig:STATIC_BACKGROUND}) allows users to register a verification of their senses, while simultaneously observing the full locomotion of virtual environment. It has also been noted that some individuals are more susceptible than others to VR sickness \cite{VRINDIVIDUALS}. Age, health, postural stability, gender, experience with the system, and many other factors can contribute to the severity of the symptoms.

\begin{figure}[th]
\centering
\includegraphics[width=0.9\textwidth]{img/static_background.png}
\caption{Static visual background, a technqiue used to reduce VR sickness symptoms (image source: \cite{STATICBACKGROUND})}
\label{fig:STATIC_BACKGROUND}
\end{figure}

\section{Locomotion in VR}
Implementing locomotion in virtual reality is one of the biggest challenges of creating comfortable and immersive VR experience. Poorly designed movement, such as sudden unexpected accelerations and rotations, can quickly induce sickness on even seasoned VR users. With the recent advancements in VR technology, numerous new locomotion techniques have been developed and researched \cite{VRHCI}. Unfortunately, there still hasn't been found the perfect approach that would work with equal efficacy across all users. Various methods have their strengths and weaknesses in terms of user experience, immersion, and input devices. 

In 2017, C. Boletsis published a systematic literature review \cite{LOCOMOTIONREVIEW} of recent studies investigating current VR locomotion techniques. In the 36 articles relevant to the research topic, he has identified the following 11 different methods of locomotion. 

\begin{itemize}
\item Arm swinging: The user stays in place and swings his arms. Body tracking devices or hand-worn controllers detect the arm movements, which are then used to control VR locomotion.
\item Chair-based: This technique uses a stool chair as an input device. While sitting on it, the user can tilt and rotate the chair. These registered inputs are translated into VR forward, backward and sideways motions.
\item Controller/joystick: The traditional input devices of video games. Using buttons for discrete input or joysticks for analog input, the user controls the movement in VR.
\item Gesture-based: Making hand gestures, such as push, tap or flying, move the user in the virtual environment. Motion sensing input devices track the gestures, which are then translated into virtual movement.
\item Head-directed: The user controls locomotion with the help of equipped HMD. Yaw, pitch and roll head motions command the direction and speed of VR movement.
\item Human joystick: This method uses a sensing board (e.g., Wii Balance Board). By leaning on it, the user can produce the backward, forward and sideways motions.
\item Real-walking: While the user moves freely within a limited physical space, body tracking devices are used to determine his position in the virtual environment.
\item Redirected walking: The user explores a virtual world that is significantly larger than the limited physical space. This approach introduces a subtle mismatch between virtual and real movements to wrap enormous virtual environment into the tracked physical space.
\item Reorientation: As in the case of redirected walking, the user physically walks without restrictions while exploring unlimited virtual world. This technique modifies the rotational gain of the user, which forces him to unknowingly reorient himself when he meets the boundaries of the physical space.
\item Teleportation: By making a pointing gesture or using a controller, the user indicates where he wants to move in the scene. He is then immediately teleported to a new location he has just pointed.
\item Walking-in-place: The user pretends to be walking while remaining stationary. Input is registered with motion trackers or with the help of treadmill-like navigation devices.
\end{itemize}

In his literature review, C. Boletsis proposes locomotion typology with the four different classification categories (Figure \ref{fig:TYPOLOGY}). The first of them is interaction type, which focuses on the methods of triggering VR navigation. Artificial methods utilize various input devices, while physical methods exploit motion cues using body tracking devices. Next category, VR motion type, separates techniques into continues and non-continues motions. Continues motion offers smooth, uninterrupted movement, whereas non-continues motion provides instantaneous teleport transitions. VR interaction space is the third classification category. It can be limited due to the constraints of the physical environment, or it can be open and support unlimited movement in virtual environment. Lastly, the techniques can be classified into four distinct VR locomotion types:

\begin{itemize}
\item Motion-based: These locomotion techniques support continuous movement in open interaction space with some kind of physical motions. This type includes methods such as arm swinging, gesture-based, redirected walking, reorientation, and walking-in-place locomotion.
\item Room scale-based: The techniques that support continuous movement and utilize interaction with physical movement. However, as opposed to motion-based methods, the interaction space is limited by the physical environment's size. From the previously mentioned techniques, only real-walking locomotion matches this description.
\item Controller-based: The methods under this type use various controllers for continues movement in open interaction spaces. Locomotion techniques such as human joystick, chair-based, head-directed, and joystick-based fall under this type.
\item Teleportation-based: This locomotion type uses artificial interactions in open interaction spaces. It differs from controller-based methods in non-continues movement, as the user is immediately teleported to a selected position. This type includes free and fixpoint teleport techniques.
\end{itemize}

\begin{figure}[th]
\centering
\includegraphics[width=1\textwidth]{img/locomotion_typology.png}
\caption{The VR locomotion typology (image source: \cite{LOCOMOTIONREVIEW})}
\label{fig:TYPOLOGY}
\end{figure}

Although there are many promising solutions to VR locomotion, currently only a handful of them are used in mainstream VR games. Approaches like real-walking, reorientation, or redirected-walking locomotion offer creative way of exploring the virtual world, however, they often require dedicated and expensive hardware, large tracking space, and can be tiring in longer VR sessions. For these reasons VR developers mostly implement regular controller-based locomotion techniques. Unfortunately, joystick-based continuous motion is known for inducing VR sickness symptoms. This problem is now partly solved with effective dynamic field-of-view adjustments \cite{DYNAMICFOD}. Many popular VR games, such as Robo Recall, Raw Data and Vanishing Realms, adopt Point \& Teleport locomotion to reduce the effects of motion sickness \cite{TELEPORTATIONGAMES}. This technique uses a pointing curve as the indicator for the teleportation path (Figure \ref{fig:TELEPORTATIONCURVEIMAGE}). Although it has been proved by some researchers to be the least discomforting locomotion method for the VR users, its drawback is that it can also reduce a sense of presence within a VR environment \cite{TELEPORTATIONEFFECTS}. An alternative fixpoint teleport locomotion, which allows the player to quickly move between predefined node positions, can be applied to preserve accessibility while maintaining the feeling of presence \cite{NODEBASEDTELEPORTATION}.

\begin{figure}[th]
\centering
\includegraphics[width=0.9\textwidth]{img/teleportation_curve.png}
\caption{Point \& Teleport locomotion technique that uses a curve as the indicator for the teleportation path (image source: \cite{TELEPORTATIONCURVE})}
\label{fig:TELEPORTATIONCURVEIMAGE}
\end{figure}

There are several tricks and best practices for designing VR locomotion. Oculus in their developer documentation \cite{OCULUSDOC} lists general guidelines for acceleration, speed, user control, and direction of locomotion. Acceleration in VR not initiated by the user's physical movement is the main cause of discomfort. It is best to avoid any unpredictable increases of the size, frequency, and duration of the acceleration. Manipulations of speed, such as slow-motion or unnaturally rapid velocity, have been reported to be less discomforting than a normal human pace. In the real world, humans most often move forward or stand in place. When the VR movement is necessary, it is best to prevent backing up or strafing as it can be unusual optic flow pattern to the users. Open environments are also generally more comfortable. Moving the users through enclosed spaces, such as tunnels or hallways, should be avoided.

\section{VR head collision problem}

Although modern VR games use different techniques to move the player's avatar in the virtual environment, most of them have one thing in common. They use tracking systems to estimate the position and rotation of the user's head. The player now gets the ability to look around the virtual world with physical head movements, without the need of additional input controllers. Head tracking increases the feeling of presence in virtual reality. It also drastically reduces VR sickness symptoms that are caused due to the mismatch between vestibular and visual senses \cite{HEADTRACKINGSYMPTOMS}. However, positional head tracking introduces a significant problem with head-object collisions in the virtual scene.

In traditional video games, a virtual camera used to render a game world is under full control of the game logic. It usually follows the player's avatar in first-person or third-person view, or it is set during the game creation to some fixed position and orientation. The game engine then renders an image of the virtual world for that camera setup. For the most part, video games use collision detection systems to prevent the intersection of two or more objects on the game scene. If the player collides with a game object, such as a table or a wall, the player's avatar and the camera stops moving in that direction. The user is under the impression that he has been physically blocked by the object. 

With the addition of head tracking to VR games, some of the camera control rules change or become obsolete. Almost all VR games are playable only in the first-person view. This makes the players feel immersed and present in the virtual world. The camera's position still follows the avatar's head, but the camera's rotation is now set using the player’s real-world head rotation. Unfortunately, head tracking also changes the way how head-object collisions are normally resolved in games. The problem arises when the player's head should collide with some game object, but the user keeps moving his head in real-world without any obstructions. There are researchers that experiment with a haptic system that can simulate walls or heavy objects via electrical muscle stimulation \cite{HEPTICSYSTEM}. However, it could take years before this technology works properly and becomes available to the mainstream VR users. With the recent popularity of VR games, there is a need for solution that could be adapted by current developers.

\begin{figure}[th]
\centering
\includegraphics[width=0.9\textwidth]{img/clipping.png}
\caption{In the game Fallout 4 VR, players can see through the walls when they lean against them (image source: \cite{redditfallout})}
\label{fig:FALLOUTCLIPPING}
\end{figure}

Many developers ignore the head collision problem, and they decide to not handle it in any way \cite{OCULUSDOCCLIPPING}. If the player positions himself close to some obstructing object in the virtual scene, and then starts leaning in the direction of the collision, the head rotation will still update according to the real-world position. The player will be able to look inside or past the colliding object. This results in unexpected clipping artifacts (Figure \ref{fig:FALLOUTCLIPPING}) that break the feeling of presence in virtual world. The ability to see through the game objects can also have undesirable effects on game mechanics. In games with the Point \& Teleport locomotion, the players can cheat by teleporting through the walls to skip harder game areas \cite{SKYRIMTELEPORT}. In shooter games, the players can see and shoot through the walls, giving them an unfair advantage over enemies. There is a need for solution that would at least restrict the forbidden view. For these reasons, many VR developers try various techniques for handling head collisions in their games. The most commonly used methods are:

\begin{itemize}
\item Screen fade: When the head collision is detected, the screen slowly fades to black or any other solid color (Figure \ref{fig:SCREENFADEIMAGE}). The view remains blacked-out for as long as the player's head collides with the object. Because this technique is relatively simple to implement, it attracts many VR developers looking for a quick solution to the problem. However, the method has one weakness that makes it not work well with the Point \& Teleport locomotion technique. For example, the player can unintentionally teleport to some head-object colliding position. He is then stuck in a black void, and he doesn't know in what direction he should move his head to escape it.

\item Object fade: Rather than fading black the whole screen, only parts of the colliding objects fade out as the camera gets close to them (Figure \ref{fig:OBJECTFADEIMAGE}). This solution has a couple of advantages. The player can easily recognize which specific objects are colliding with him. If he unintentionally teleports to some head-object colliding position, he can maneuver his head out of the highlighted objects. He can also completely avoid any collisions by tracking the color of surrounding objects. If some object starts to fade, the player knows to not get any closer to it.

\item Camera collider: In this solution, the head tracking is not treated as an independent controller for the virtual camera, but as another type of input device that moves the avatar \cite{CAMERACOLLIDER}. The camera still follows the player's avatar head, but this time it is surrounded by a kinematic rigidbody collider. The collisions are handled exactly like they are in non-VR games; the player's body, including the head, is unable to get past virtual walls and other obstacles. If the player decides to keep moving his head forward, despite the fact that there is a virtual wall in front of him, he will feel like he is pushing himself backwards from the wall using his head.

\item Camera push-back: If the player collides with some object for a couple of seconds, he is slowly pushed backwards until he leaves the object's boundaries. The head tracking is disabled during the duration of the push-back effect. This technique is often used in older open-world games that were nowadays ported to VR, such as Skyrim VR or Fallout 4 VR. Many players of these games reported that the camera push-back is frustrating to experience, and it makes them feel dizzy \cite{redditfallout}\cite{SKYRIMVRPUSHBACK}\cite{PUSHBACKFEEDBACK}. The reason is that the push-back effect takes control of camera movements away from the player, and this tends to increase VR sickness symptoms.
\end{itemize}

\begin{figure}[th]
\centering
\includegraphics[width=1\textwidth]{img/screen_fade.png}
\caption{Time slice example of the screen fade technique. When the head collision is detected, the screen slowly fades to black (image source: \cite{SCREENFADE})}
\label{fig:SCREENFADEIMAGE}
\end{figure}

\begin{figure}[th]
\centering
\includegraphics[width=1\textwidth]{img/object_fade.png}
\caption{Time slice example of the object fade technique. The closer the camera gets to the collision, the more the colliding object is faded out (image source: \cite{OBJECTFADE})}
\label{fig:OBJECTFADEIMAGE}
\end{figure}

There are also many other, less popular ideas for solving the head collision problem. For instance, instead of the camera push-back, the players can be instantly teleported to a nearby collision-free position. The solid color in the screen fade technique can be replaced by any image or virtual scene the developer chooses. Some of VR developers design the whole gameplay around collisions. The main mechanic of these games is to collect or destroy some objects that disappear when they collide with the player, making it impossible to look inside them. In 2018, a group of researchers \cite{COMPARISONCOLLISION} experimented with a technique they called ``not there yet''. Their approach works similar to the camera collider method. If the user collides with some obstacle, a projection on the horizontal plane of penetration vector is added to the player's position. This effectively moves the user away from the obstacle, preventing him from looking inside it. The researchers compared their solution to the screen fade method in terms of immersion and VR sickness. Unfortunately, they found out that while their approach yielded better immersion results, it contributed more to VR sickness symptoms.

